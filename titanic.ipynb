{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "titanic = pandas.read_csv(\"kaggle_titanic/train.csv\")\n",
    "test_data = pandas.read_csv(\"kaggle_titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "def get_age_group(age):\n",
    "    if age < 15:\n",
    "        return 0\n",
    "    if age < 50:\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "# new features\n",
    "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
    "titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))\n",
    "titanic[\"Title\"] = titanic[\"Name\"].apply(get_title)\n",
    "\n",
    "\n",
    "columns_labels = preprocessing.LabelEncoder()\n",
    "train_columns_to_encode = ['Sex', 'Embarked', 'Title']\n",
    "\n",
    "for col in train_columns_to_encode:\n",
    "    titanic[col] = columns_labels.fit_transform(titanic[col])\n",
    "    \n",
    "titanic[\"Age\"] = scaler.fit_transform(titanic[\"Age\"])\n",
    "# titanic[\"Embarked\"] = scaler.fit_transform(titanic[\"Embarked\"].astype(float))\n",
    "# titanic[\"Parch\"] = scaler.fit_transform(titanic[\"Parch\"].astype(float))\n",
    "# titanic[\"Pclass\"] = scaler.fit_transform(titanic[\"Pclass\"].astype(float))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features exctractin\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Embarked\"]\n",
    "\n",
    "# selector = SelectKBest(f_classif, k=5)\n",
    "# selector.fit(titanic[predictors], titanic[\"Survived\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_to_vect(classification):\n",
    "    cls_count = 2\n",
    "    vect = []\n",
    "    for cls in classification:\n",
    "        v = [0] * cls_count\n",
    "        v[cls] = 1\n",
    "        vect.append(v)\n",
    "    return np.array(vect)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Construct neural network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "# alg = LogisticRegression(random_state=1)\n",
    "# alg = GradientBoostingClassifier()\n",
    "nn = Sequential()\n",
    "nn.add(Dense(len(predictors), output_dim=5, activation='tanh'))\n",
    "nn.add(Dense(5, output_dim=5, activation='tanh'))\n",
    "nn.add(Dropout(0.1))\n",
    "nn.add(Dense(5, output_dim=2, activation='softmax'))\n",
    "nn.compile(loss='binary_crossentropy', optimizer='Adam')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8047138047138047\n"
     ]
    }
   ],
   "source": [
    "def perc_score(actual, prediction):\n",
    "    error = 0\n",
    "    N = len(predictions)\n",
    "    for i in range(N):\n",
    "        if predictions[i] == actual.iloc[i]:\n",
    "            error += 1\n",
    "    return float(error) / N\n",
    "\n",
    "kf = KFold(titanic.shape[0], n_folds=10, random_state=1)\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_predictors = titanic[predictors].as_matrix()[train,:]\n",
    "    target = class_to_vect(titanic.Survived.as_matrix())\n",
    "    target_train = class_to_vect(titanic.Survived.iloc[train].as_matrix())\n",
    "    nn.fit(train_predictors, target[train], nb_epoch=100, show_accuracy=True)\n",
    "    test_predictions = nn.predict_classes(titanic[predictors].as_matrix()[test,:])\n",
    "    predictions.append(test_predictions)\n",
    "predictions = np.concatenate(predictions)\n",
    "\n",
    "print(perc_score(titanic.Survived, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# processing test data \n",
    "\n",
    "test_data[\"Age\"] = scaler.fit_transform(test_data[\"Age\"].fillna(titanic[\"Age\"].median()))\n",
    "test_data[\"Embarked\"] = test_data[\"Embarked\"].fillna(\"S\")\n",
    "test_data[\"Fare\"] = test_data[\"Fare\"].fillna(titanic[\"Fare\"].median())\n",
    "\n",
    "# new features\n",
    "test_data[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"]\n",
    "test_data[\"NameLength\"] = test_data[\"Name\"].apply(lambda x: len(x))\n",
    "test_data[\"Title\"] = test_data[\"Name\"].apply(get_title)\n",
    "\n",
    "\n",
    "\n",
    "for col in train_columns_to_encode:\n",
    "    test_data[col] = columns_labels.fit_transform(test_data[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "891/891 [==============================] - 0s - loss: 0.4683 - acc: 0.7969     \n",
      "Epoch 1\n",
      "891/891 [==============================] - 0s - loss: 0.4592 - acc: 0.8025     \n",
      "Epoch 2\n",
      "891/891 [==============================] - 0s - loss: 0.4656 - acc: 0.8002     \n",
      "Epoch 3\n",
      "891/891 [==============================] - 0s - loss: 0.4644 - acc: 0.8013     \n",
      "Epoch 4\n",
      "891/891 [==============================] - 0s - loss: 0.4594 - acc: 0.8047     \n",
      "Epoch 5\n",
      "891/891 [==============================] - 0s - loss: 0.4655 - acc: 0.8025     \n",
      "Epoch 6\n",
      "891/891 [==============================] - 0s - loss: 0.4515 - acc: 0.7946     \n",
      "Epoch 7\n",
      "891/891 [==============================] - 0s - loss: 0.4585 - acc: 0.8036     \n",
      "Epoch 8\n",
      "891/891 [==============================] - 0s - loss: 0.4562 - acc: 0.8025     \n",
      "Epoch 9\n",
      "891/891 [==============================] - 0s - loss: 0.4666 - acc: 0.8025     \n",
      "Epoch 10\n",
      "891/891 [==============================] - 0s - loss: 0.4564 - acc: 0.8070     \n",
      "Epoch 11\n",
      "891/891 [==============================] - 0s - loss: 0.4573 - acc: 0.8070     \n",
      "Epoch 12\n",
      "891/891 [==============================] - 0s - loss: 0.4578 - acc: 0.8036     \n",
      "Epoch 13\n",
      "891/891 [==============================] - 0s - loss: 0.4559 - acc: 0.8081     \n",
      "Epoch 14\n",
      "891/891 [==============================] - 0s - loss: 0.4535 - acc: 0.8103     \n",
      "Epoch 15\n",
      "891/891 [==============================] - 0s - loss: 0.4549 - acc: 0.8025     \n",
      "Epoch 16\n",
      "891/891 [==============================] - 0s - loss: 0.4523 - acc: 0.8036     \n",
      "Epoch 17\n",
      "891/891 [==============================] - 0s - loss: 0.4512 - acc: 0.8002     \n",
      "Epoch 18\n",
      "891/891 [==============================] - 0s - loss: 0.4505 - acc: 0.8047     \n",
      "Epoch 19\n",
      "891/891 [==============================] - 0s - loss: 0.4572 - acc: 0.8047     \n",
      "Epoch 20\n",
      "891/891 [==============================] - 0s - loss: 0.4564 - acc: 0.8103     \n",
      "Epoch 21\n",
      "891/891 [==============================] - 0s - loss: 0.4544 - acc: 0.8058     \n",
      "Epoch 22\n",
      "891/891 [==============================] - 0s - loss: 0.4555 - acc: 0.8047     \n",
      "Epoch 23\n",
      "891/891 [==============================] - 0s - loss: 0.4480 - acc: 0.8013     \n",
      "Epoch 24\n",
      "891/891 [==============================] - 0s - loss: 0.4528 - acc: 0.8058     \n",
      "Epoch 25\n",
      "891/891 [==============================] - 0s - loss: 0.4530 - acc: 0.8070     \n",
      "Epoch 26\n",
      "891/891 [==============================] - 0s - loss: 0.4536 - acc: 0.8081     \n",
      "Epoch 27\n",
      "891/891 [==============================] - 0s - loss: 0.4561 - acc: 0.8081     \n",
      "Epoch 28\n",
      "891/891 [==============================] - 0s - loss: 0.4446 - acc: 0.8126     \n",
      "Epoch 29\n",
      "891/891 [==============================] - 0s - loss: 0.4496 - acc: 0.8081     \n",
      "Epoch 30\n",
      "891/891 [==============================] - 0s - loss: 0.4495 - acc: 0.8081     \n",
      "Epoch 31\n",
      "891/891 [==============================] - 0s - loss: 0.4501 - acc: 0.8070     \n",
      "Epoch 32\n",
      "891/891 [==============================] - 0s - loss: 0.4511 - acc: 0.8070     \n",
      "Epoch 33\n",
      "891/891 [==============================] - 0s - loss: 0.4481 - acc: 0.8081     \n",
      "Epoch 34\n",
      "891/891 [==============================] - 0s - loss: 0.4460 - acc: 0.8070     \n",
      "Epoch 35\n",
      "891/891 [==============================] - 0s - loss: 0.4557 - acc: 0.8092     \n",
      "Epoch 36\n",
      "891/891 [==============================] - 0s - loss: 0.4516 - acc: 0.8092     \n",
      "Epoch 37\n",
      "891/891 [==============================] - 0s - loss: 0.4471 - acc: 0.8103     \n",
      "Epoch 38\n",
      "891/891 [==============================] - 0s - loss: 0.4517 - acc: 0.8058     \n",
      "Epoch 39\n",
      "891/891 [==============================] - 0s - loss: 0.4526 - acc: 0.8058     \n",
      "Epoch 40\n",
      "891/891 [==============================] - 0s - loss: 0.4486 - acc: 0.8103     \n",
      "Epoch 41\n",
      "891/891 [==============================] - 0s - loss: 0.4455 - acc: 0.8137     \n",
      "Epoch 42\n",
      "891/891 [==============================] - 0s - loss: 0.4499 - acc: 0.8092     \n",
      "Epoch 43\n",
      "891/891 [==============================] - 0s - loss: 0.4482 - acc: 0.8081     \n",
      "Epoch 44\n",
      "891/891 [==============================] - 0s - loss: 0.4473 - acc: 0.8081     \n",
      "Epoch 45\n",
      "891/891 [==============================] - 0s - loss: 0.4453 - acc: 0.8047     \n",
      "Epoch 46\n",
      "891/891 [==============================] - 0s - loss: 0.4465 - acc: 0.8058     \n",
      "Epoch 47\n",
      "891/891 [==============================] - 0s - loss: 0.4454 - acc: 0.8092     \n",
      "Epoch 48\n",
      "891/891 [==============================] - 0s - loss: 0.4458 - acc: 0.8103     \n",
      "Epoch 49\n",
      "891/891 [==============================] - 0s - loss: 0.4452 - acc: 0.8103     \n",
      "Epoch 50\n",
      "891/891 [==============================] - 0s - loss: 0.4510 - acc: 0.8081     \n",
      "Epoch 51\n",
      "891/891 [==============================] - 0s - loss: 0.4470 - acc: 0.8058     \n",
      "Epoch 52\n",
      "891/891 [==============================] - 0s - loss: 0.4399 - acc: 0.8126     \n",
      "Epoch 53\n",
      "891/891 [==============================] - 0s - loss: 0.4390 - acc: 0.8047     \n",
      "Epoch 54\n",
      "891/891 [==============================] - 0s - loss: 0.4435 - acc: 0.8092     \n",
      "Epoch 55\n",
      "891/891 [==============================] - 0s - loss: 0.4455 - acc: 0.8092     \n",
      "Epoch 56\n",
      "891/891 [==============================] - 0s - loss: 0.4420 - acc: 0.8070     \n",
      "Epoch 57\n",
      "891/891 [==============================] - 0s - loss: 0.4450 - acc: 0.8013     \n",
      "Epoch 58\n",
      "891/891 [==============================] - 0s - loss: 0.4459 - acc: 0.8047     \n",
      "Epoch 59\n",
      "891/891 [==============================] - 0s - loss: 0.4429 - acc: 0.8047     \n",
      "Epoch 60\n",
      "891/891 [==============================] - 0s - loss: 0.4409 - acc: 0.8058     \n",
      "Epoch 61\n",
      "891/891 [==============================] - 0s - loss: 0.4443 - acc: 0.8058     \n",
      "Epoch 62\n",
      "891/891 [==============================] - 0s - loss: 0.4355 - acc: 0.8070     \n",
      "Epoch 63\n",
      "891/891 [==============================] - 0s - loss: 0.4356 - acc: 0.8171     \n",
      "Epoch 64\n",
      "891/891 [==============================] - 0s - loss: 0.4448 - acc: 0.8070     \n",
      "Epoch 65\n",
      "891/891 [==============================] - 0s - loss: 0.4432 - acc: 0.8092     \n",
      "Epoch 66\n",
      "891/891 [==============================] - 0s - loss: 0.4389 - acc: 0.8148     \n",
      "Epoch 67\n",
      "891/891 [==============================] - 0s - loss: 0.4425 - acc: 0.8081     \n",
      "Epoch 68\n",
      "891/891 [==============================] - 0s - loss: 0.4402 - acc: 0.8103     \n",
      "Epoch 69\n",
      "891/891 [==============================] - 0s - loss: 0.4366 - acc: 0.8103     \n",
      "Epoch 70\n",
      "891/891 [==============================] - 0s - loss: 0.4424 - acc: 0.8058     \n",
      "Epoch 71\n",
      "891/891 [==============================] - 0s - loss: 0.4430 - acc: 0.8092     \n",
      "Epoch 72\n",
      "891/891 [==============================] - 0s - loss: 0.4406 - acc: 0.8126     \n",
      "Epoch 73\n",
      "891/891 [==============================] - 0s - loss: 0.4366 - acc: 0.8070     \n",
      "Epoch 74\n",
      "891/891 [==============================] - 0s - loss: 0.4432 - acc: 0.8114     \n",
      "Epoch 75\n",
      "891/891 [==============================] - 0s - loss: 0.4390 - acc: 0.8126     \n",
      "Epoch 76\n",
      "891/891 [==============================] - 0s - loss: 0.4351 - acc: 0.8126     \n",
      "Epoch 77\n",
      "891/891 [==============================] - 0s - loss: 0.4398 - acc: 0.8103     \n",
      "Epoch 78\n",
      "891/891 [==============================] - 0s - loss: 0.4433 - acc: 0.8081     \n",
      "Epoch 79\n",
      "891/891 [==============================] - 0s - loss: 0.4439 - acc: 0.8103     \n",
      "Epoch 80\n",
      "891/891 [==============================] - 0s - loss: 0.4352 - acc: 0.8103     \n",
      "Epoch 81\n",
      "891/891 [==============================] - 0s - loss: 0.4412 - acc: 0.8103     \n",
      "Epoch 82\n",
      "891/891 [==============================] - 0s - loss: 0.4343 - acc: 0.8047     \n",
      "Epoch 83\n",
      "891/891 [==============================] - 0s - loss: 0.4441 - acc: 0.8126     \n",
      "Epoch 84\n",
      "891/891 [==============================] - 0s - loss: 0.4378 - acc: 0.8114     \n",
      "Epoch 85\n",
      "891/891 [==============================] - 0s - loss: 0.4350 - acc: 0.8114     \n",
      "Epoch 86\n",
      "891/891 [==============================] - 0s - loss: 0.4323 - acc: 0.8092     \n",
      "Epoch 87\n",
      "891/891 [==============================] - 0s - loss: 0.4396 - acc: 0.8058     \n",
      "Epoch 88\n",
      "891/891 [==============================] - 0s - loss: 0.4376 - acc: 0.8058     \n",
      "Epoch 89\n",
      "891/891 [==============================] - 0s - loss: 0.4337 - acc: 0.8148     \n",
      "Epoch 90\n",
      "891/891 [==============================] - 0s - loss: 0.4344 - acc: 0.8159     \n",
      "Epoch 91\n",
      "891/891 [==============================] - 0s - loss: 0.4338 - acc: 0.8103     \n",
      "Epoch 92\n",
      "891/891 [==============================] - 0s - loss: 0.4410 - acc: 0.8103     \n",
      "Epoch 93\n",
      "891/891 [==============================] - 0s - loss: 0.4378 - acc: 0.8070     \n",
      "Epoch 94\n",
      "891/891 [==============================] - 0s - loss: 0.4333 - acc: 0.8148     \n",
      "Epoch 95\n",
      "891/891 [==============================] - 0s - loss: 0.4300 - acc: 0.8092     \n",
      "Epoch 96\n",
      "891/891 [==============================] - 0s - loss: 0.4316 - acc: 0.8148     \n",
      "Epoch 97\n",
      "891/891 [==============================] - 0s - loss: 0.4316 - acc: 0.8171     \n",
      "Epoch 98\n",
      "891/891 [==============================] - 0s - loss: 0.4331 - acc: 0.8159     \n",
      "Epoch 99\n",
      "891/891 [==============================] - 0s - loss: 0.4372 - acc: 0.8103     \n",
      "418/418 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "# predict test data\n",
    "\n",
    "# alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "nn.fit(titanic[predictors].as_matrix(), class_to_vect(titanic.Survived.as_matrix()), nb_epoch=100, show_accuracy=True)\n",
    "predictions = nn.predict_classes(test_data[predictors].as_matrix())\n",
    "\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": test_data[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "submission.to_csv(\"kaggle_titanic/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
