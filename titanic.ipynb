{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "titanic = pandas.read_csv(\"kaggle_titanic/train.csv\")\n",
    "test_data = pandas.read_csv(\"kaggle_titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "def get_age_group(age):\n",
    "    if age < 15:\n",
    "        return 0\n",
    "    if age < 50:\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "scaler = preprocessing.MinMaxScaler()\n",
    "\n",
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "# new features\n",
    "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
    "titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))\n",
    "titanic[\"Title\"] = titanic[\"Name\"].apply(get_title)\n",
    "titanic[\"Age\"] = scaler.fit_transform(titanic[\"Age\"])\n",
    "\n",
    "columns_labels = preprocessing.LabelEncoder()\n",
    "train_columns_to_encode = ['Sex', 'Embarked', 'Title']\n",
    "\n",
    "for col in train_columns_to_encode:\n",
    "    titanic[col] = columns_labels.fit_transform(titanic[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features exctractin\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Embarked\", \"Title\"]\n",
    "\n",
    "# selector = SelectKBest(f_classif, k=5)\n",
    "# selector.fit(titanic[predictors], titanic[\"Survived\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_to_vect(classification):\n",
    "    cls_count = 2\n",
    "    vect = []\n",
    "    for cls in classification:\n",
    "        v = [0] * cls_count\n",
    "        v[cls] = 1\n",
    "        vect.append(v)\n",
    "    return np.array(vect)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two outputs approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 720 samples, validate on 81 samples\n",
      "Epoch 0\n",
      "720/720 [==============================] - 0s - loss: 0.2742 - acc: 0.3806 - val_loss: 0.2719 - val_acc: 0.3580\n",
      "Epoch 1\n",
      "720/720 [==============================] - 0s - loss: 0.2678 - acc: 0.3819 - val_loss: 0.2659 - val_acc: 0.3580\n",
      "Epoch 2\n",
      "720/720 [==============================] - 0s - loss: 0.2626 - acc: 0.3819 - val_loss: 0.2610 - val_acc: 0.3704\n",
      "Epoch 3\n",
      "720/720 [==============================] - 0s - loss: 0.2584 - acc: 0.3694 - val_loss: 0.2568 - val_acc: 0.3086\n",
      "Epoch 4\n",
      "720/720 [==============================] - 0s - loss: 0.2549 - acc: 0.3639 - val_loss: 0.2534 - val_acc: 0.3457\n",
      "Epoch 5\n",
      "720/720 [==============================] - 0s - loss: 0.2521 - acc: 0.4181 - val_loss: 0.2507 - val_acc: 0.4444\n",
      "Epoch 6\n",
      "720/720 [==============================] - 0s - loss: 0.2497 - acc: 0.5458 - val_loss: 0.2483 - val_acc: 0.6790\n",
      "Epoch 7\n",
      "720/720 [==============================] - 0s - loss: 0.2478 - acc: 0.6153 - val_loss: 0.2462 - val_acc: 0.6420\n",
      "Epoch 8\n",
      "720/720 [==============================] - 0s - loss: 0.2461 - acc: 0.6181 - val_loss: 0.2444 - val_acc: 0.6420\n",
      "Epoch 9\n",
      "720/720 [==============================] - 0s - loss: 0.2446 - acc: 0.6222 - val_loss: 0.2428 - val_acc: 0.6420\n",
      "Epoch 10\n",
      "720/720 [==============================] - 0s - loss: 0.2433 - acc: 0.6236 - val_loss: 0.2414 - val_acc: 0.6296\n",
      "Epoch 11\n",
      "720/720 [==============================] - 0s - loss: 0.2422 - acc: 0.6167 - val_loss: 0.2402 - val_acc: 0.6296\n",
      "Epoch 12\n",
      "720/720 [==============================] - 0s - loss: 0.2413 - acc: 0.6167 - val_loss: 0.2391 - val_acc: 0.6296\n",
      "Epoch 13\n",
      "720/720 [==============================] - 0s - loss: 0.2405 - acc: 0.6167 - val_loss: 0.2381 - val_acc: 0.6296\n",
      "Epoch 14\n",
      "720/720 [==============================] - 0s - loss: 0.2397 - acc: 0.6167 - val_loss: 0.2372 - val_acc: 0.6296\n",
      "Epoch 15\n",
      "720/720 [==============================] - 0s - loss: 0.2391 - acc: 0.6167 - val_loss: 0.2365 - val_acc: 0.6420\n",
      "Epoch 16\n",
      "720/720 [==============================] - 0s - loss: 0.2385 - acc: 0.6167 - val_loss: 0.2357 - val_acc: 0.6420\n",
      "Epoch 17\n",
      "720/720 [==============================] - 0s - loss: 0.2379 - acc: 0.6167 - val_loss: 0.2350 - val_acc: 0.6420\n",
      "Epoch 18\n",
      "720/720 [==============================] - 0s - loss: 0.2375 - acc: 0.6167 - val_loss: 0.2345 - val_acc: 0.6420\n",
      "Epoch 19\n",
      "720/720 [==============================] - 0s - loss: 0.2371 - acc: 0.6167 - val_loss: 0.2339 - val_acc: 0.6420\n",
      "Epoch 20\n",
      "720/720 [==============================] - 0s - loss: 0.2367 - acc: 0.6181 - val_loss: 0.2334 - val_acc: 0.6420\n",
      "Epoch 21\n",
      "720/720 [==============================] - 0s - loss: 0.2364 - acc: 0.6181 - val_loss: 0.2329 - val_acc: 0.6420\n",
      "Epoch 22\n",
      "720/720 [==============================] - 0s - loss: 0.2360 - acc: 0.6181 - val_loss: 0.2325 - val_acc: 0.6420\n",
      "Epoch 23\n",
      "720/720 [==============================] - 0s - loss: 0.2358 - acc: 0.6181 - val_loss: 0.2322 - val_acc: 0.6420\n",
      "Epoch 24\n",
      "720/720 [==============================] - 0s - loss: 0.2355 - acc: 0.6181 - val_loss: 0.2318 - val_acc: 0.6420\n",
      "Epoch 25\n",
      "720/720 [==============================] - 0s - loss: 0.2353 - acc: 0.6194 - val_loss: 0.2315 - val_acc: 0.6420\n",
      "Epoch 26\n",
      "720/720 [==============================] - 0s - loss: 0.2351 - acc: 0.6194 - val_loss: 0.2312 - val_acc: 0.6420\n",
      "Epoch 27\n",
      "720/720 [==============================] - 0s - loss: 0.2349 - acc: 0.6194 - val_loss: 0.2309 - val_acc: 0.6420\n",
      "Epoch 28\n",
      "720/720 [==============================] - 0s - loss: 0.2347 - acc: 0.6194 - val_loss: 0.2306 - val_acc: 0.6420\n",
      "Epoch 29\n",
      "720/720 [==============================] - 0s - loss: 0.2345 - acc: 0.6194 - val_loss: 0.2304 - val_acc: 0.6420\n",
      "90/90 [==============================] - 0s\n",
      "Train on 721 samples, validate on 81 samples\n",
      "Epoch 0\n",
      "721/721 [==============================] - 0s - loss: 0.2394 - acc: 0.5936 - val_loss: 0.2303 - val_acc: 0.6420\n",
      "Epoch 1\n",
      "721/721 [==============================] - 0s - loss: 0.2393 - acc: 0.5936 - val_loss: 0.2302 - val_acc: 0.6420\n",
      "Epoch 2\n",
      "721/721 [==============================] - 0s - loss: 0.2392 - acc: 0.5936 - val_loss: 0.2301 - val_acc: 0.6420\n",
      "Epoch 3\n",
      "721/721 [==============================] - 0s - loss: 0.2391 - acc: 0.5936 - val_loss: 0.2300 - val_acc: 0.6420\n",
      "Epoch 4\n",
      "721/721 [==============================] - 0s - loss: 0.2390 - acc: 0.5936 - val_loss: 0.2299 - val_acc: 0.6420\n",
      "Epoch 5\n",
      "721/721 [==============================] - 0s - loss: 0.2389 - acc: 0.5936 - val_loss: 0.2297 - val_acc: 0.6420\n",
      "Epoch 6\n",
      "721/721 [==============================] - 0s - loss: 0.2388 - acc: 0.5936 - val_loss: 0.2296 - val_acc: 0.6420\n",
      "Epoch 7\n",
      "721/721 [==============================] - 0s - loss: 0.2387 - acc: 0.5936 - val_loss: 0.2295 - val_acc: 0.6420\n",
      "Epoch 8\n",
      "721/721 [==============================] - 0s - loss: 0.2385 - acc: 0.5936 - val_loss: 0.2293 - val_acc: 0.6420\n",
      "Epoch 9\n",
      "721/721 [==============================] - 0s - loss: 0.2384 - acc: 0.5936 - val_loss: 0.2292 - val_acc: 0.6420\n",
      "Epoch 10\n",
      "721/721 [==============================] - 0s - loss: 0.2383 - acc: 0.5936 - val_loss: 0.2291 - val_acc: 0.6420\n",
      "Epoch 11\n",
      "721/721 [==============================] - 0s - loss: 0.2383 - acc: 0.5936 - val_loss: 0.2290 - val_acc: 0.6420\n",
      "Epoch 12\n",
      "721/721 [==============================] - 0s - loss: 0.2381 - acc: 0.5936 - val_loss: 0.2289 - val_acc: 0.6420\n",
      "Epoch 13\n",
      "721/721 [==============================] - 0s - loss: 0.2380 - acc: 0.5936 - val_loss: 0.2288 - val_acc: 0.6420\n",
      "Epoch 14\n",
      "721/721 [==============================] - 0s - loss: 0.2379 - acc: 0.5936 - val_loss: 0.2287 - val_acc: 0.6420\n",
      "Epoch 15\n",
      "721/721 [==============================] - 0s - loss: 0.2378 - acc: 0.5922 - val_loss: 0.2286 - val_acc: 0.6420\n",
      "Epoch 16\n",
      "721/721 [==============================] - 0s - loss: 0.2377 - acc: 0.5922 - val_loss: 0.2284 - val_acc: 0.6420\n",
      "Epoch 17\n",
      "721/721 [==============================] - 0s - loss: 0.2376 - acc: 0.5922 - val_loss: 0.2284 - val_acc: 0.6420\n",
      "Epoch 18\n",
      "721/721 [==============================] - 0s - loss: 0.2375 - acc: 0.5922 - val_loss: 0.2283 - val_acc: 0.6420\n",
      "Epoch 19\n",
      "721/721 [==============================] - 0s - loss: 0.2374 - acc: 0.5908 - val_loss: 0.2281 - val_acc: 0.6420\n",
      "Epoch 20\n",
      "721/721 [==============================] - 0s - loss: 0.2373 - acc: 0.5908 - val_loss: 0.2280 - val_acc: 0.6420\n",
      "Epoch 21\n",
      "721/721 [==============================] - 0s - loss: 0.2372 - acc: 0.5908 - val_loss: 0.2279 - val_acc: 0.6420\n",
      "Epoch 22\n",
      "721/721 [==============================] - 0s - loss: 0.2370 - acc: 0.5908 - val_loss: 0.2278 - val_acc: 0.6420\n",
      "Epoch 23\n",
      "721/721 [==============================] - 0s - loss: 0.2369 - acc: 0.5908 - val_loss: 0.2276 - val_acc: 0.6420\n",
      "Epoch 24\n",
      "721/721 [==============================] - 0s - loss: 0.2368 - acc: 0.5908 - val_loss: 0.2275 - val_acc: 0.6420\n",
      "Epoch 25\n",
      "721/721 [==============================] - 0s - loss: 0.2367 - acc: 0.5908 - val_loss: 0.2274 - val_acc: 0.6420\n",
      "Epoch 26\n",
      "721/721 [==============================] - 0s - loss: 0.2366 - acc: 0.5908 - val_loss: 0.2272 - val_acc: 0.6420\n",
      "Epoch 27\n",
      "721/721 [==============================] - 0s - loss: 0.2365 - acc: 0.5908 - val_loss: 0.2271 - val_acc: 0.6420\n",
      "Epoch 28\n",
      "721/721 [==============================] - 0s - loss: 0.2364 - acc: 0.5908 - val_loss: 0.2270 - val_acc: 0.6420\n",
      "Epoch 29\n",
      "721/721 [==============================] - 0s - loss: 0.2363 - acc: 0.5908 - val_loss: 0.2269 - val_acc: 0.6420\n",
      "89/89 [==============================] - 0s\n",
      "Train on 721 samples, validate on 81 samples\n",
      "Epoch 0\n",
      "721/721 [==============================] - 0s - loss: 0.2326 - acc: 0.6103 - val_loss: 0.2267 - val_acc: 0.6420\n",
      "Epoch 1\n",
      "721/721 [==============================] - 0s - loss: 0.2325 - acc: 0.6103 - val_loss: 0.2263 - val_acc: 0.6420\n",
      "Epoch 2\n",
      "721/721 [==============================] - 0s - loss: 0.2323 - acc: 0.6103 - val_loss: 0.2261 - val_acc: 0.6420\n",
      "Epoch 3\n",
      "721/721 [==============================] - 0s - loss: 0.2321 - acc: 0.6103 - val_loss: 0.2259 - val_acc: 0.6420\n",
      "Epoch 4\n",
      "721/721 [==============================] - 0s - loss: 0.2320 - acc: 0.6103 - val_loss: 0.2256 - val_acc: 0.6420\n",
      "Epoch 5\n",
      "721/721 [==============================] - 0s - loss: 0.2318 - acc: 0.6103 - val_loss: 0.2255 - val_acc: 0.6420\n",
      "Epoch 6\n",
      "721/721 [==============================] - 0s - loss: 0.2317 - acc: 0.6103 - val_loss: 0.2253 - val_acc: 0.6420\n",
      "Epoch 7\n",
      "721/721 [==============================] - 0s - loss: 0.2316 - acc: 0.6103 - val_loss: 0.2251 - val_acc: 0.6420\n",
      "Epoch 8\n",
      "721/721 [==============================] - 0s - loss: 0.2314 - acc: 0.6103 - val_loss: 0.2249 - val_acc: 0.6420\n",
      "Epoch 9\n",
      "721/721 [==============================] - 0s - loss: 0.2313 - acc: 0.6103 - val_loss: 0.2247 - val_acc: 0.6420\n",
      "Epoch 10\n",
      "721/721 [==============================] - 0s - loss: 0.2312 - acc: 0.6103 - val_loss: 0.2245 - val_acc: 0.6420\n",
      "Epoch 11\n",
      "721/721 [==============================] - 0s - loss: 0.2310 - acc: 0.6103 - val_loss: 0.2243 - val_acc: 0.6420\n",
      "Epoch 12\n",
      "721/721 [==============================] - 0s - loss: 0.2309 - acc: 0.6103 - val_loss: 0.2242 - val_acc: 0.6420\n",
      "Epoch 13\n",
      "721/721 [==============================] - 0s - loss: 0.2308 - acc: 0.6103 - val_loss: 0.2240 - val_acc: 0.6420\n",
      "Epoch 14\n",
      "721/721 [==============================] - 0s - loss: 0.2306 - acc: 0.6103 - val_loss: 0.2238 - val_acc: 0.6420\n",
      "Epoch 15\n",
      "721/721 [==============================] - 0s - loss: 0.2305 - acc: 0.6103 - val_loss: 0.2236 - val_acc: 0.6420\n",
      "Epoch 16\n",
      "721/721 [==============================] - 0s - loss: 0.2304 - acc: 0.6103 - val_loss: 0.2235 - val_acc: 0.6420\n",
      "Epoch 17\n",
      "721/721 [==============================] - 0s - loss: 0.2302 - acc: 0.6103 - val_loss: 0.2233 - val_acc: 0.6420\n",
      "Epoch 18\n",
      "721/721 [==============================] - 0s - loss: 0.2301 - acc: 0.6103 - val_loss: 0.2232 - val_acc: 0.6420\n",
      "Epoch 19\n",
      "721/721 [==============================] - 0s - loss: 0.2300 - acc: 0.6103 - val_loss: 0.2230 - val_acc: 0.6420\n",
      "Epoch 20\n",
      "721/721 [==============================] - 0s - loss: 0.2298 - acc: 0.6103 - val_loss: 0.2228 - val_acc: 0.6420\n",
      "Epoch 21\n",
      "721/721 [==============================] - 0s - loss: 0.2297 - acc: 0.6103 - val_loss: 0.2227 - val_acc: 0.6420\n",
      "Epoch 22\n",
      "721/721 [==============================] - 0s - loss: 0.2296 - acc: 0.6103 - val_loss: 0.2225 - val_acc: 0.6420\n",
      "Epoch 23\n",
      "721/721 [==============================] - 0s - loss: 0.2294 - acc: 0.6103 - val_loss: 0.2223 - val_acc: 0.6420\n",
      "Epoch 24\n",
      "721/721 [==============================] - 0s - loss: 0.2293 - acc: 0.6103 - val_loss: 0.2222 - val_acc: 0.6420\n",
      "Epoch 25\n",
      "721/721 [==============================] - 0s - loss: 0.2292 - acc: 0.6103 - val_loss: 0.2220 - val_acc: 0.6420\n",
      "Epoch 26\n",
      "721/721 [==============================] - 0s - loss: 0.2290 - acc: 0.6103 - val_loss: 0.2218 - val_acc: 0.6420\n",
      "Epoch 27\n",
      "721/721 [==============================] - 0s - loss: 0.2289 - acc: 0.6117 - val_loss: 0.2216 - val_acc: 0.6420\n",
      "Epoch 28\n",
      "721/721 [==============================] - 0s - loss: 0.2287 - acc: 0.6117 - val_loss: 0.2214 - val_acc: 0.6420\n",
      "Epoch 29\n",
      "721/721 [==============================] - 0s - loss: 0.2286 - acc: 0.6117 - val_loss: 0.2213 - val_acc: 0.6420\n",
      "89/89 [==============================] - 0s\n",
      "Train on 721 samples, validate on 81 samples\n",
      "Epoch 0\n",
      "721/721 [==============================] - 0s - loss: 0.2252 - acc: 0.6283 - val_loss: 0.2210 - val_acc: 0.6420\n",
      "Epoch 1\n",
      "721/721 [==============================] - 0s - loss: 0.2251 - acc: 0.6283 - val_loss: 0.2208 - val_acc: 0.6420\n",
      "Epoch 2\n",
      "721/721 [==============================] - 0s - loss: 0.2249 - acc: 0.6283 - val_loss: 0.2206 - val_acc: 0.6420\n",
      "Epoch 3\n",
      "721/721 [==============================] - 0s - loss: 0.2248 - acc: 0.6283 - val_loss: 0.2204 - val_acc: 0.6420\n",
      "Epoch 4\n",
      "721/721 [==============================] - 0s - loss: 0.2246 - acc: 0.6283 - val_loss: 0.2202 - val_acc: 0.6420\n",
      "Epoch 5\n",
      "721/721 [==============================] - 0s - loss: 0.2244 - acc: 0.6283 - val_loss: 0.2200 - val_acc: 0.6420\n",
      "Epoch 6\n",
      "721/721 [==============================] - 0s - loss: 0.2243 - acc: 0.6283 - val_loss: 0.2198 - val_acc: 0.6420\n",
      "Epoch 7\n",
      "721/721 [==============================] - 0s - loss: 0.2241 - acc: 0.6283 - val_loss: 0.2196 - val_acc: 0.6420\n",
      "Epoch 8\n",
      "721/721 [==============================] - 0s - loss: 0.2240 - acc: 0.6283 - val_loss: 0.2194 - val_acc: 0.6420\n",
      "Epoch 9\n",
      "721/721 [==============================] - 0s - loss: 0.2238 - acc: 0.6283 - val_loss: 0.2192 - val_acc: 0.6420\n",
      "Epoch 10\n",
      "721/721 [==============================] - 0s - loss: 0.2237 - acc: 0.6283 - val_loss: 0.2190 - val_acc: 0.6420\n",
      "Epoch 11\n",
      "721/721 [==============================] - 0s - loss: 0.2235 - acc: 0.6283 - val_loss: 0.2188 - val_acc: 0.6420\n",
      "Epoch 12\n",
      "721/721 [==============================] - 0s - loss: 0.2234 - acc: 0.6297 - val_loss: 0.2186 - val_acc: 0.6420\n",
      "Epoch 13\n",
      "721/721 [==============================] - 0s - loss: 0.2232 - acc: 0.6297 - val_loss: 0.2184 - val_acc: 0.6420\n",
      "Epoch 14\n",
      "721/721 [==============================] - 0s - loss: 0.2231 - acc: 0.6338 - val_loss: 0.2182 - val_acc: 0.6420\n",
      "Epoch 15\n",
      "721/721 [==============================] - 0s - loss: 0.2229 - acc: 0.6325 - val_loss: 0.2180 - val_acc: 0.6420\n",
      "Epoch 16\n",
      "721/721 [==============================] - 0s - loss: 0.2228 - acc: 0.6338 - val_loss: 0.2178 - val_acc: 0.6420\n",
      "Epoch 17\n",
      "721/721 [==============================] - 0s - loss: 0.2226 - acc: 0.6338 - val_loss: 0.2176 - val_acc: 0.6420\n",
      "Epoch 18\n",
      "721/721 [==============================] - 0s - loss: 0.2224 - acc: 0.6338 - val_loss: 0.2174 - val_acc: 0.6420\n",
      "Epoch 19\n",
      "721/721 [==============================] - 0s - loss: 0.2223 - acc: 0.6338 - val_loss: 0.2172 - val_acc: 0.6420\n",
      "Epoch 20\n",
      "721/721 [==============================] - 0s - loss: 0.2221 - acc: 0.6338 - val_loss: 0.2171 - val_acc: 0.6420\n",
      "Epoch 21\n",
      "721/721 [==============================] - 0s - loss: 0.2220 - acc: 0.6352 - val_loss: 0.2168 - val_acc: 0.6420\n",
      "Epoch 22\n",
      "721/721 [==============================] - 0s - loss: 0.2218 - acc: 0.6352 - val_loss: 0.2166 - val_acc: 0.6420\n",
      "Epoch 23\n",
      "721/721 [==============================] - 0s - loss: 0.2216 - acc: 0.6366 - val_loss: 0.2164 - val_acc: 0.6420\n",
      "Epoch 24\n",
      "721/721 [==============================] - 0s - loss: 0.2215 - acc: 0.6338 - val_loss: 0.2162 - val_acc: 0.6420\n",
      "Epoch 25\n",
      "721/721 [==============================] - 0s - loss: 0.2213 - acc: 0.6366 - val_loss: 0.2160 - val_acc: 0.6420\n",
      "Epoch 26\n",
      "721/721 [==============================] - 0s - loss: 0.2212 - acc: 0.6366 - val_loss: 0.2158 - val_acc: 0.6420\n",
      "Epoch 27\n",
      "721/721 [==============================] - 0s - loss: 0.2210 - acc: 0.6366 - val_loss: 0.2156 - val_acc: 0.6296\n",
      "Epoch 28\n",
      "721/721 [==============================] - 0s - loss: 0.2209 - acc: 0.6366 - val_loss: 0.2154 - val_acc: 0.6296\n",
      "Epoch 29\n",
      "721/721 [==============================] - 0s - loss: 0.2207 - acc: 0.6366 - val_loss: 0.2152 - val_acc: 0.6296\n",
      "89/89 [==============================] - 0s\n",
      "Train on 721 samples, validate on 81 samples\n",
      "Epoch 0\n",
      "721/721 [==============================] - 0s - loss: 0.2233 - acc: 0.6241 - val_loss: 0.2150 - val_acc: 0.6296\n",
      "Epoch 1\n",
      "721/721 [==============================] - 0s - loss: 0.2232 - acc: 0.6241 - val_loss: 0.2149 - val_acc: 0.6296\n",
      "Epoch 2\n",
      "721/721 [==============================] - 0s - loss: 0.2230 - acc: 0.6255 - val_loss: 0.2147 - val_acc: 0.6296\n",
      "Epoch 3\n",
      "721/721 [==============================] - 0s - loss: 0.2228 - acc: 0.6269 - val_loss: 0.2145 - val_acc: 0.6296\n",
      "Epoch 4\n",
      "721/721 [==============================] - 0s - loss: 0.2226 - acc: 0.6269 - val_loss: 0.2142 - val_acc: 0.6296\n",
      "Epoch 5\n",
      "721/721 [==============================] - 0s - loss: 0.2225 - acc: 0.6269 - val_loss: 0.2140 - val_acc: 0.6296\n",
      "Epoch 6\n",
      "721/721 [==============================] - 0s - loss: 0.2223 - acc: 0.6269 - val_loss: 0.2138 - val_acc: 0.6296\n",
      "Epoch 7\n",
      "721/721 [==============================] - 0s - loss: 0.2221 - acc: 0.6283 - val_loss: 0.2136 - val_acc: 0.6296\n",
      "Epoch 8\n",
      "721/721 [==============================] - 0s - loss: 0.2219 - acc: 0.6311 - val_loss: 0.2134 - val_acc: 0.6420\n",
      "Epoch 9\n",
      "721/721 [==============================] - 0s - loss: 0.2217 - acc: 0.6325 - val_loss: 0.2132 - val_acc: 0.6420\n",
      "Epoch 10\n",
      "721/721 [==============================] - 0s - loss: 0.2215 - acc: 0.6338 - val_loss: 0.2130 - val_acc: 0.6420\n",
      "Epoch 11\n",
      "721/721 [==============================] - 0s - loss: 0.2214 - acc: 0.6352 - val_loss: 0.2127 - val_acc: 0.6420\n",
      "Epoch 12\n",
      "721/721 [==============================] - 0s - loss: 0.2212 - acc: 0.6352 - val_loss: 0.2125 - val_acc: 0.6420\n",
      "Epoch 13\n",
      "721/721 [==============================] - 0s - loss: 0.2210 - acc: 0.6352 - val_loss: 0.2122 - val_acc: 0.6420\n",
      "Epoch 14\n",
      "721/721 [==============================] - 0s - loss: 0.2208 - acc: 0.6352 - val_loss: 0.2119 - val_acc: 0.6420\n",
      "Epoch 15\n",
      "721/721 [==============================] - 0s - loss: 0.2206 - acc: 0.6352 - val_loss: 0.2116 - val_acc: 0.6420\n",
      "Epoch 16\n",
      "721/721 [==============================] - 0s - loss: 0.2205 - acc: 0.6352 - val_loss: 0.2114 - val_acc: 0.6420\n",
      "Epoch 17\n",
      "721/721 [==============================] - 0s - loss: 0.2202 - acc: 0.6352 - val_loss: 0.2111 - val_acc: 0.6420\n",
      "Epoch 18\n",
      "721/721 [==============================] - 0s - loss: 0.2200 - acc: 0.6352 - val_loss: 0.2108 - val_acc: 0.6420\n",
      "Epoch 19\n",
      "721/721 [==============================] - 0s - loss: 0.2198 - acc: 0.6352 - val_loss: 0.2106 - val_acc: 0.6543\n",
      "Epoch 20\n",
      "721/721 [==============================] - 0s - loss: 0.2197 - acc: 0.6380 - val_loss: 0.2104 - val_acc: 0.6543\n",
      "Epoch 21\n",
      "721/721 [==============================] - 0s - loss: 0.2194 - acc: 0.6394 - val_loss: 0.2101 - val_acc: 0.6543\n",
      "Epoch 22\n",
      "721/721 [==============================] - 0s - loss: 0.2192 - acc: 0.6394 - val_loss: 0.2098 - val_acc: 0.6543\n",
      "Epoch 23\n",
      "721/721 [==============================] - 0s - loss: 0.2190 - acc: 0.6408 - val_loss: 0.2095 - val_acc: 0.6543\n",
      "Epoch 24\n",
      "721/721 [==============================] - 0s - loss: 0.2188 - acc: 0.6436 - val_loss: 0.2092 - val_acc: 0.6543\n",
      "Epoch 25\n",
      "721/721 [==============================] - 0s - loss: 0.2186 - acc: 0.6491 - val_loss: 0.2089 - val_acc: 0.6543\n",
      "Epoch 26\n",
      "721/721 [==============================] - 0s - loss: 0.2184 - acc: 0.6449 - val_loss: 0.2086 - val_acc: 0.6667\n",
      "Epoch 27\n",
      "721/721 [==============================] - 0s - loss: 0.2182 - acc: 0.6588 - val_loss: 0.2083 - val_acc: 0.6667\n",
      "Epoch 28\n",
      "721/721 [==============================] - 0s - loss: 0.2180 - acc: 0.6574 - val_loss: 0.2080 - val_acc: 0.6667\n",
      "Epoch 29\n",
      "721/721 [==============================] - 0s - loss: 0.2178 - acc: 0.6574 - val_loss: 0.2078 - val_acc: 0.6667\n",
      "89/89 [==============================] - 0s\n",
      "Train on 721 samples, validate on 81 samples\n",
      "Epoch 0\n",
      "721/721 [==============================] - 0s - loss: 0.2190 - acc: 0.6533 - val_loss: 0.2076 - val_acc: 0.6914\n",
      "Epoch 1\n",
      "721/721 [==============================] - 0s - loss: 0.2186 - acc: 0.6519 - val_loss: 0.2073 - val_acc: 0.7160\n",
      "Epoch 2\n",
      "721/721 [==============================] - 0s - loss: 0.2186 - acc: 0.6546 - val_loss: 0.2070 - val_acc: 0.7284\n",
      "Epoch 3\n",
      "721/721 [==============================] - 0s - loss: 0.2182 - acc: 0.6616 - val_loss: 0.2067 - val_acc: 0.7284\n",
      "Epoch 4\n",
      "721/721 [==============================] - 0s - loss: 0.2180 - acc: 0.6644 - val_loss: 0.2064 - val_acc: 0.7654\n",
      "Epoch 5\n",
      "721/721 [==============================] - 0s - loss: 0.2178 - acc: 0.6657 - val_loss: 0.2061 - val_acc: 0.7654\n",
      "Epoch 6\n",
      "721/721 [==============================] - 0s - loss: 0.2176 - acc: 0.6685 - val_loss: 0.2057 - val_acc: 0.7654\n",
      "Epoch 7\n",
      "721/721 [==============================] - 0s - loss: 0.2172 - acc: 0.6713 - val_loss: 0.2053 - val_acc: 0.7654\n",
      "Epoch 8\n",
      "721/721 [==============================] - 0s - loss: 0.2170 - acc: 0.6671 - val_loss: 0.2050 - val_acc: 0.7654\n",
      "Epoch 9\n",
      "721/721 [==============================] - 0s - loss: 0.2167 - acc: 0.6727 - val_loss: 0.2046 - val_acc: 0.7778\n",
      "Epoch 10\n",
      "721/721 [==============================] - 0s - loss: 0.2165 - acc: 0.6713 - val_loss: 0.2043 - val_acc: 0.7778\n",
      "Epoch 11\n",
      "721/721 [==============================] - 0s - loss: 0.2162 - acc: 0.6713 - val_loss: 0.2039 - val_acc: 0.7778\n",
      "Epoch 12\n",
      "721/721 [==============================] - 0s - loss: 0.2160 - acc: 0.6768 - val_loss: 0.2034 - val_acc: 0.7778\n",
      "Epoch 13\n",
      "721/721 [==============================] - 0s - loss: 0.2159 - acc: 0.6755 - val_loss: 0.2030 - val_acc: 0.7778\n",
      "Epoch 14\n",
      "721/721 [==============================] - 0s - loss: 0.2155 - acc: 0.6755 - val_loss: 0.2026 - val_acc: 0.7778\n",
      "Epoch 15\n",
      "721/721 [==============================] - 0s - loss: 0.2153 - acc: 0.6755 - val_loss: 0.2025 - val_acc: 0.7654\n",
      "Epoch 16\n",
      "721/721 [==============================] - 0s - loss: 0.2150 - acc: 0.6879 - val_loss: 0.2019 - val_acc: 0.7654\n",
      "Epoch 17\n",
      "721/721 [==============================] - 0s - loss: 0.2148 - acc: 0.6852 - val_loss: 0.2017 - val_acc: 0.7654\n",
      "Epoch 18\n",
      "721/721 [==============================] - 0s - loss: 0.2145 - acc: 0.6907 - val_loss: 0.2012 - val_acc: 0.7654\n",
      "Epoch 19\n",
      "721/721 [==============================] - 0s - loss: 0.2142 - acc: 0.6921 - val_loss: 0.2009 - val_acc: 0.7654\n",
      "Epoch 20\n",
      "721/721 [==============================] - 0s - loss: 0.2139 - acc: 0.6935 - val_loss: 0.2005 - val_acc: 0.7654\n",
      "Epoch 21\n",
      "721/721 [==============================] - 0s - loss: 0.2136 - acc: 0.6949 - val_loss: 0.2000 - val_acc: 0.7654\n",
      "Epoch 22\n",
      "721/721 [==============================] - 0s - loss: 0.2134 - acc: 0.6921 - val_loss: 0.1996 - val_acc: 0.7284\n",
      "Epoch 23\n",
      "721/721 [==============================] - 0s - loss: 0.2131 - acc: 0.6963 - val_loss: 0.1991 - val_acc: 0.7284\n",
      "Epoch 24\n",
      "721/721 [==============================] - 0s - loss: 0.2128 - acc: 0.6963 - val_loss: 0.1985 - val_acc: 0.7284\n",
      "Epoch 25\n",
      "721/721 [==============================] - 0s - loss: 0.2125 - acc: 0.6907 - val_loss: 0.1982 - val_acc: 0.7284\n",
      "Epoch 26\n",
      "721/721 [==============================] - 0s - loss: 0.2122 - acc: 0.6963 - val_loss: 0.1979 - val_acc: 0.7407\n",
      "Epoch 27\n",
      "721/721 [==============================] - 0s - loss: 0.2119 - acc: 0.6949 - val_loss: 0.1975 - val_acc: 0.7407\n",
      "Epoch 28\n",
      "721/721 [==============================] - 0s - loss: 0.2116 - acc: 0.6921 - val_loss: 0.1974 - val_acc: 0.7407\n",
      "Epoch 29\n",
      "721/721 [==============================] - 0s - loss: 0.2113 - acc: 0.6935 - val_loss: 0.1969 - val_acc: 0.7531\n",
      "89/89 [==============================] - 0s\n",
      "Train on 721 samples, validate on 81 samples\n",
      "Epoch 0\n",
      "721/721 [==============================] - 0s - loss: 0.2087 - acc: 0.6990 - val_loss: 0.1960 - val_acc: 0.7407\n",
      "Epoch 1\n",
      "721/721 [==============================] - 0s - loss: 0.2084 - acc: 0.7018 - val_loss: 0.1953 - val_acc: 0.7407\n",
      "Epoch 2\n",
      "721/721 [==============================] - 0s - loss: 0.2081 - acc: 0.6949 - val_loss: 0.1948 - val_acc: 0.7407\n",
      "Epoch 3\n",
      "721/721 [==============================] - 0s - loss: 0.2078 - acc: 0.6963 - val_loss: 0.1945 - val_acc: 0.7407\n",
      "Epoch 4\n",
      "721/721 [==============================] - 0s - loss: 0.2075 - acc: 0.6963 - val_loss: 0.1940 - val_acc: 0.7407\n",
      "Epoch 5\n",
      "721/721 [==============================] - 0s - loss: 0.2072 - acc: 0.6935 - val_loss: 0.1937 - val_acc: 0.7407\n",
      "Epoch 6\n",
      "721/721 [==============================] - 0s - loss: 0.2069 - acc: 0.6921 - val_loss: 0.1933 - val_acc: 0.7531\n",
      "Epoch 7\n",
      "721/721 [==============================] - 0s - loss: 0.2066 - acc: 0.6963 - val_loss: 0.1930 - val_acc: 0.7407\n",
      "Epoch 8\n",
      "721/721 [==============================] - 0s - loss: 0.2063 - acc: 0.6949 - val_loss: 0.1926 - val_acc: 0.7407\n",
      "Epoch 9\n",
      "721/721 [==============================] - 0s - loss: 0.2061 - acc: 0.7018 - val_loss: 0.1923 - val_acc: 0.7407\n",
      "Epoch 10\n",
      "721/721 [==============================] - 0s - loss: 0.2058 - acc: 0.7032 - val_loss: 0.1918 - val_acc: 0.7407\n",
      "Epoch 11\n",
      "721/721 [==============================] - 0s - loss: 0.2054 - acc: 0.7074 - val_loss: 0.1913 - val_acc: 0.7407\n",
      "Epoch 12\n",
      "721/721 [==============================] - 0s - loss: 0.2052 - acc: 0.7032 - val_loss: 0.1909 - val_acc: 0.7407\n",
      "Epoch 13\n",
      "721/721 [==============================] - 0s - loss: 0.2049 - acc: 0.6976 - val_loss: 0.1907 - val_acc: 0.7407\n",
      "Epoch 14\n",
      "721/721 [==============================] - 0s - loss: 0.2047 - acc: 0.7074 - val_loss: 0.1905 - val_acc: 0.7407\n",
      "Epoch 15\n",
      "721/721 [==============================] - 0s - loss: 0.2044 - acc: 0.7129 - val_loss: 0.1898 - val_acc: 0.7407\n",
      "Epoch 16\n",
      "721/721 [==============================] - 0s - loss: 0.2041 - acc: 0.7032 - val_loss: 0.1897 - val_acc: 0.7407\n",
      "Epoch 17\n",
      "721/721 [==============================] - 0s - loss: 0.2037 - acc: 0.7171 - val_loss: 0.1890 - val_acc: 0.7407\n",
      "Epoch 18\n",
      "721/721 [==============================] - 0s - loss: 0.2035 - acc: 0.7143 - val_loss: 0.1888 - val_acc: 0.7407\n",
      "Epoch 19\n",
      "721/721 [==============================] - 0s - loss: 0.2031 - acc: 0.7157 - val_loss: 0.1884 - val_acc: 0.7407\n",
      "Epoch 20\n",
      "721/721 [==============================] - 0s - loss: 0.2029 - acc: 0.7157 - val_loss: 0.1877 - val_acc: 0.7407\n",
      "Epoch 21\n",
      "721/721 [==============================] - 0s - loss: 0.2026 - acc: 0.7101 - val_loss: 0.1875 - val_acc: 0.7407\n",
      "Epoch 22\n",
      "721/721 [==============================] - 0s - loss: 0.2023 - acc: 0.7129 - val_loss: 0.1873 - val_acc: 0.7407\n",
      "Epoch 23\n",
      "721/721 [==============================] - 0s - loss: 0.2021 - acc: 0.7143 - val_loss: 0.1869 - val_acc: 0.7407\n",
      "Epoch 24\n",
      "721/721 [==============================] - 0s - loss: 0.2018 - acc: 0.7101 - val_loss: 0.1867 - val_acc: 0.7407\n",
      "Epoch 25\n",
      "721/721 [==============================] - 0s - loss: 0.2016 - acc: 0.7157 - val_loss: 0.1861 - val_acc: 0.7407\n",
      "Epoch 26\n",
      "721/721 [==============================] - 0s - loss: 0.2013 - acc: 0.7143 - val_loss: 0.1856 - val_acc: 0.7407\n",
      "Epoch 27\n",
      "721/721 [==============================] - 0s - loss: 0.2011 - acc: 0.7143 - val_loss: 0.1852 - val_acc: 0.7407\n",
      "Epoch 28\n",
      "721/721 [==============================] - 0s - loss: 0.2008 - acc: 0.7143 - val_loss: 0.1850 - val_acc: 0.7407\n",
      "Epoch 29\n",
      "721/721 [==============================] - 0s - loss: 0.2005 - acc: 0.7101 - val_loss: 0.1850 - val_acc: 0.7407\n",
      "89/89 [==============================] - 0s\n",
      "Train on 721 samples, validate on 81 samples\n",
      "Epoch 0\n",
      "721/721 [==============================] - 0s - loss: 0.2016 - acc: 0.7157 - val_loss: 0.1847 - val_acc: 0.7407\n",
      "Epoch 1\n",
      "721/721 [==============================] - 0s - loss: 0.2014 - acc: 0.7184 - val_loss: 0.1842 - val_acc: 0.7407\n",
      "Epoch 2\n",
      "721/721 [==============================] - 0s - loss: 0.2013 - acc: 0.7198 - val_loss: 0.1837 - val_acc: 0.7407\n",
      "Epoch 3\n",
      "721/721 [==============================] - 0s - loss: 0.2011 - acc: 0.7129 - val_loss: 0.1836 - val_acc: 0.7407\n",
      "Epoch 4\n",
      "721/721 [==============================] - 0s - loss: 0.2005 - acc: 0.7184 - val_loss: 0.1837 - val_acc: 0.7407\n",
      "Epoch 5\n",
      "721/721 [==============================] - 0s - loss: 0.2003 - acc: 0.7184 - val_loss: 0.1834 - val_acc: 0.7407\n",
      "Epoch 6\n",
      "721/721 [==============================] - 0s - loss: 0.2000 - acc: 0.7212 - val_loss: 0.1829 - val_acc: 0.7407\n",
      "Epoch 7\n",
      "721/721 [==============================] - 0s - loss: 0.1997 - acc: 0.7212 - val_loss: 0.1829 - val_acc: 0.7531\n",
      "Epoch 8\n",
      "721/721 [==============================] - 0s - loss: 0.1995 - acc: 0.7198 - val_loss: 0.1827 - val_acc: 0.7531\n",
      "Epoch 9\n",
      "721/721 [==============================] - 0s - loss: 0.1993 - acc: 0.7226 - val_loss: 0.1826 - val_acc: 0.7531\n",
      "Epoch 10\n",
      "721/721 [==============================] - 0s - loss: 0.1991 - acc: 0.7254 - val_loss: 0.1815 - val_acc: 0.7407\n",
      "Epoch 11\n",
      "721/721 [==============================] - 0s - loss: 0.1987 - acc: 0.7226 - val_loss: 0.1813 - val_acc: 0.7407\n",
      "Epoch 12\n",
      "721/721 [==============================] - 0s - loss: 0.1984 - acc: 0.7212 - val_loss: 0.1812 - val_acc: 0.7531\n",
      "Epoch 13\n",
      "721/721 [==============================] - 0s - loss: 0.1983 - acc: 0.7240 - val_loss: 0.1808 - val_acc: 0.7531\n",
      "Epoch 14\n",
      "721/721 [==============================] - 0s - loss: 0.1978 - acc: 0.7254 - val_loss: 0.1804 - val_acc: 0.7531\n",
      "Epoch 15\n",
      "721/721 [==============================] - 0s - loss: 0.1977 - acc: 0.7268 - val_loss: 0.1797 - val_acc: 0.7531\n",
      "Epoch 16\n",
      "721/721 [==============================] - 0s - loss: 0.1974 - acc: 0.7226 - val_loss: 0.1804 - val_acc: 0.7531\n",
      "Epoch 17\n",
      "721/721 [==============================] - 0s - loss: 0.1973 - acc: 0.7282 - val_loss: 0.1801 - val_acc: 0.7531\n",
      "Epoch 18\n",
      "721/721 [==============================] - 0s - loss: 0.1969 - acc: 0.7282 - val_loss: 0.1800 - val_acc: 0.7531\n",
      "Epoch 19\n",
      "721/721 [==============================] - 0s - loss: 0.1967 - acc: 0.7268 - val_loss: 0.1795 - val_acc: 0.7531\n",
      "Epoch 20\n",
      "721/721 [==============================] - 0s - loss: 0.1963 - acc: 0.7295 - val_loss: 0.1792 - val_acc: 0.7531\n",
      "Epoch 21\n",
      "721/721 [==============================] - 0s - loss: 0.1962 - acc: 0.7295 - val_loss: 0.1785 - val_acc: 0.7531\n",
      "Epoch 22\n",
      "721/721 [==============================] - 0s - loss: 0.1958 - acc: 0.7282 - val_loss: 0.1783 - val_acc: 0.7531\n",
      "Epoch 23\n",
      "721/721 [==============================] - 0s - loss: 0.1956 - acc: 0.7323 - val_loss: 0.1777 - val_acc: 0.7531\n",
      "Epoch 24\n",
      "721/721 [==============================] - 0s - loss: 0.1954 - acc: 0.7309 - val_loss: 0.1773 - val_acc: 0.7531\n",
      "Epoch 25\n",
      "721/721 [==============================] - 0s - loss: 0.1952 - acc: 0.7282 - val_loss: 0.1779 - val_acc: 0.7531\n",
      "Epoch 26\n",
      "721/721 [==============================] - 0s - loss: 0.1951 - acc: 0.7295 - val_loss: 0.1771 - val_acc: 0.7531\n",
      "Epoch 27\n",
      "721/721 [==============================] - 0s - loss: 0.1950 - acc: 0.7295 - val_loss: 0.1764 - val_acc: 0.7531\n",
      "Epoch 28\n",
      "721/721 [==============================] - 0s - loss: 0.1942 - acc: 0.7309 - val_loss: 0.1768 - val_acc: 0.7531\n",
      "Epoch 29\n",
      "721/721 [==============================] - 0s - loss: 0.1943 - acc: 0.7309 - val_loss: 0.1761 - val_acc: 0.7531\n",
      "89/89 [==============================] - 0s\n",
      "Train on 721 samples, validate on 81 samples\n",
      "Epoch 0\n",
      "721/721 [==============================] - 0s - loss: 0.1964 - acc: 0.7198 - val_loss: 0.1762 - val_acc: 0.7531\n",
      "Epoch 1\n",
      "721/721 [==============================] - 0s - loss: 0.1964 - acc: 0.7226 - val_loss: 0.1761 - val_acc: 0.7531\n",
      "Epoch 2\n",
      "721/721 [==============================] - 0s - loss: 0.1959 - acc: 0.7212 - val_loss: 0.1754 - val_acc: 0.7531\n",
      "Epoch 3\n",
      "721/721 [==============================] - 0s - loss: 0.1957 - acc: 0.7212 - val_loss: 0.1750 - val_acc: 0.7531\n",
      "Epoch 4\n",
      "721/721 [==============================] - 0s - loss: 0.1955 - acc: 0.7184 - val_loss: 0.1750 - val_acc: 0.7531\n",
      "Epoch 5\n",
      "721/721 [==============================] - 0s - loss: 0.1953 - acc: 0.7254 - val_loss: 0.1746 - val_acc: 0.7531\n",
      "Epoch 6\n",
      "721/721 [==============================] - 0s - loss: 0.1950 - acc: 0.7212 - val_loss: 0.1744 - val_acc: 0.7531\n",
      "Epoch 7\n",
      "721/721 [==============================] - 0s - loss: 0.1951 - acc: 0.7226 - val_loss: 0.1735 - val_acc: 0.7531\n",
      "Epoch 8\n",
      "721/721 [==============================] - 0s - loss: 0.1947 - acc: 0.7226 - val_loss: 0.1739 - val_acc: 0.7531\n",
      "Epoch 9\n",
      "721/721 [==============================] - 0s - loss: 0.1944 - acc: 0.7226 - val_loss: 0.1738 - val_acc: 0.7531\n",
      "Epoch 10\n",
      "721/721 [==============================] - 0s - loss: 0.1942 - acc: 0.7254 - val_loss: 0.1734 - val_acc: 0.7531\n",
      "Epoch 11\n",
      "721/721 [==============================] - 0s - loss: 0.1940 - acc: 0.7254 - val_loss: 0.1724 - val_acc: 0.7531\n",
      "Epoch 12\n",
      "721/721 [==============================] - 0s - loss: 0.1938 - acc: 0.7198 - val_loss: 0.1725 - val_acc: 0.7531\n",
      "Epoch 13\n",
      "721/721 [==============================] - 0s - loss: 0.1936 - acc: 0.7240 - val_loss: 0.1722 - val_acc: 0.7531\n",
      "Epoch 14\n",
      "721/721 [==============================] - 0s - loss: 0.1934 - acc: 0.7212 - val_loss: 0.1725 - val_acc: 0.7531\n",
      "Epoch 15\n",
      "721/721 [==============================] - 0s - loss: 0.1929 - acc: 0.7240 - val_loss: 0.1722 - val_acc: 0.7531\n",
      "Epoch 16\n",
      "721/721 [==============================] - 0s - loss: 0.1928 - acc: 0.7240 - val_loss: 0.1721 - val_acc: 0.7531\n",
      "Epoch 17\n",
      "721/721 [==============================] - 0s - loss: 0.1927 - acc: 0.7268 - val_loss: 0.1715 - val_acc: 0.7531\n",
      "Epoch 18\n",
      "721/721 [==============================] - 0s - loss: 0.1925 - acc: 0.7240 - val_loss: 0.1712 - val_acc: 0.7531\n",
      "Epoch 19\n",
      "721/721 [==============================] - 0s - loss: 0.1922 - acc: 0.7254 - val_loss: 0.1706 - val_acc: 0.7531\n",
      "Epoch 20\n",
      "721/721 [==============================] - 0s - loss: 0.1920 - acc: 0.7240 - val_loss: 0.1702 - val_acc: 0.7531\n",
      "Epoch 21\n",
      "721/721 [==============================] - 0s - loss: 0.1919 - acc: 0.7254 - val_loss: 0.1704 - val_acc: 0.7531\n",
      "Epoch 22\n",
      "721/721 [==============================] - 0s - loss: 0.1917 - acc: 0.7268 - val_loss: 0.1700 - val_acc: 0.7531\n",
      "Epoch 23\n",
      "721/721 [==============================] - 0s - loss: 0.1912 - acc: 0.7254 - val_loss: 0.1703 - val_acc: 0.7531\n",
      "Epoch 24\n",
      "721/721 [==============================] - 0s - loss: 0.1917 - acc: 0.7295 - val_loss: 0.1696 - val_acc: 0.7531\n",
      "Epoch 25\n",
      "721/721 [==============================] - 0s - loss: 0.1912 - acc: 0.7240 - val_loss: 0.1689 - val_acc: 0.7531\n",
      "Epoch 26\n",
      "721/721 [==============================] - 0s - loss: 0.1907 - acc: 0.7254 - val_loss: 0.1688 - val_acc: 0.7531\n",
      "Epoch 27\n",
      "721/721 [==============================] - 0s - loss: 0.1906 - acc: 0.7295 - val_loss: 0.1686 - val_acc: 0.7531\n",
      "Epoch 28\n",
      "721/721 [==============================] - 0s - loss: 0.1902 - acc: 0.7268 - val_loss: 0.1688 - val_acc: 0.7531\n",
      "Epoch 29\n",
      "721/721 [==============================] - 0s - loss: 0.1902 - acc: 0.7282 - val_loss: 0.1682 - val_acc: 0.7531\n",
      "89/89 [==============================] - 0s\n",
      "Train on 721 samples, validate on 81 samples\n",
      "Epoch 0\n",
      "721/721 [==============================] - 0s - loss: 0.1880 - acc: 0.7351 - val_loss: 0.1708 - val_acc: 0.7901\n",
      "Epoch 1\n",
      "721/721 [==============================] - 0s - loss: 0.1879 - acc: 0.7379 - val_loss: 0.1701 - val_acc: 0.7901\n",
      "Epoch 2\n",
      "721/721 [==============================] - 0s - loss: 0.1879 - acc: 0.7309 - val_loss: 0.1699 - val_acc: 0.7901\n",
      "Epoch 3\n",
      "721/721 [==============================] - 0s - loss: 0.1873 - acc: 0.7337 - val_loss: 0.1705 - val_acc: 0.8025\n",
      "Epoch 4\n",
      "721/721 [==============================] - 0s - loss: 0.1874 - acc: 0.7337 - val_loss: 0.1696 - val_acc: 0.7901\n",
      "Epoch 5\n",
      "721/721 [==============================] - 0s - loss: 0.1869 - acc: 0.7323 - val_loss: 0.1699 - val_acc: 0.8025\n",
      "Epoch 6\n",
      "721/721 [==============================] - 0s - loss: 0.1869 - acc: 0.7365 - val_loss: 0.1690 - val_acc: 0.7901\n",
      "Epoch 7\n",
      "721/721 [==============================] - 0s - loss: 0.1863 - acc: 0.7365 - val_loss: 0.1689 - val_acc: 0.8025\n",
      "Epoch 8\n",
      "721/721 [==============================] - 0s - loss: 0.1862 - acc: 0.7365 - val_loss: 0.1693 - val_acc: 0.8025\n",
      "Epoch 9\n",
      "721/721 [==============================] - 0s - loss: 0.1860 - acc: 0.7379 - val_loss: 0.1683 - val_acc: 0.7901\n",
      "Epoch 10\n",
      "721/721 [==============================] - 0s - loss: 0.1856 - acc: 0.7365 - val_loss: 0.1684 - val_acc: 0.8025\n",
      "Epoch 11\n",
      "721/721 [==============================] - 0s - loss: 0.1854 - acc: 0.7379 - val_loss: 0.1683 - val_acc: 0.8025\n",
      "Epoch 12\n",
      "721/721 [==============================] - 0s - loss: 0.1852 - acc: 0.7365 - val_loss: 0.1675 - val_acc: 0.8025\n",
      "Epoch 13\n",
      "721/721 [==============================] - 0s - loss: 0.1854 - acc: 0.7379 - val_loss: 0.1675 - val_acc: 0.8025\n",
      "Epoch 14\n",
      "721/721 [==============================] - 0s - loss: 0.1847 - acc: 0.7379 - val_loss: 0.1674 - val_acc: 0.8025\n",
      "Epoch 15\n",
      "721/721 [==============================] - 0s - loss: 0.1845 - acc: 0.7365 - val_loss: 0.1669 - val_acc: 0.8025\n",
      "Epoch 16\n",
      "721/721 [==============================] - 0s - loss: 0.1843 - acc: 0.7393 - val_loss: 0.1670 - val_acc: 0.8025\n",
      "Epoch 17\n",
      "721/721 [==============================] - 0s - loss: 0.1841 - acc: 0.7393 - val_loss: 0.1670 - val_acc: 0.8025\n",
      "Epoch 18\n",
      "721/721 [==============================] - 0s - loss: 0.1838 - acc: 0.7379 - val_loss: 0.1659 - val_acc: 0.8025\n",
      "Epoch 19\n",
      "721/721 [==============================] - 0s - loss: 0.1837 - acc: 0.7448 - val_loss: 0.1673 - val_acc: 0.8025\n",
      "Epoch 20\n",
      "721/721 [==============================] - 0s - loss: 0.1836 - acc: 0.7448 - val_loss: 0.1655 - val_acc: 0.8025\n",
      "Epoch 21\n",
      "721/721 [==============================] - 0s - loss: 0.1833 - acc: 0.7406 - val_loss: 0.1652 - val_acc: 0.8025\n",
      "Epoch 22\n",
      "721/721 [==============================] - 0s - loss: 0.1832 - acc: 0.7406 - val_loss: 0.1650 - val_acc: 0.8025\n",
      "Epoch 23\n",
      "721/721 [==============================] - 0s - loss: 0.1827 - acc: 0.7448 - val_loss: 0.1654 - val_acc: 0.8025\n",
      "Epoch 24\n",
      "721/721 [==============================] - 0s - loss: 0.1826 - acc: 0.7379 - val_loss: 0.1646 - val_acc: 0.8025\n",
      "Epoch 25\n",
      "721/721 [==============================] - 0s - loss: 0.1822 - acc: 0.7434 - val_loss: 0.1644 - val_acc: 0.8025\n",
      "Epoch 26\n",
      "721/721 [==============================] - 0s - loss: 0.1820 - acc: 0.7434 - val_loss: 0.1645 - val_acc: 0.8025\n",
      "Epoch 27\n",
      "721/721 [==============================] - 0s - loss: 0.1818 - acc: 0.7420 - val_loss: 0.1646 - val_acc: 0.8025\n",
      "Epoch 28\n",
      "721/721 [==============================] - 0s - loss: 0.1816 - acc: 0.7406 - val_loss: 0.1647 - val_acc: 0.8025\n",
      "Epoch 29\n",
      "721/721 [==============================] - 0s - loss: 0.1814 - acc: 0.7448 - val_loss: 0.1634 - val_acc: 0.8025\n",
      "89/89 [==============================] - 0s\n",
      "[0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 1 1 1 0 0 0 0 0 0 0 0 1 1 1 0 1 0 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 1 0 0 1 1 0\n",
      " 0 0 1 0 0 1 0 0 1 1 0 0 0 0 0 0 0 1 0 1 0 1 1 0 0 0 0 1 1 0 0 0 1 0 0 0 0\n",
      " 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 1 0 0 0 1 0 0 0 0 0 0\n",
      " 0 0 0 0 1 0 0 0 0 0 1 0 0 0 0 1 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 0\n",
      " 0 0 0 0 1 0 1 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 1 1 0\n",
      " 0 0 0 1 1 1 0 1 1 0 0 0 0 1 1 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 1 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 1 0 1 0 0 0 0 0 0 1 0 1 0 0\n",
      " 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 1 0 0 1 0 0 0 0\n",
      " 0 1 0 0 0 0 1 0 0 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 1 1 0\n",
      " 0 0 1 1 1 1 1 1 0 0 0 1 0 0 1 0 1 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 0 1 1 1\n",
      " 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "# classification and cross validation\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "# alg = LogisticRegression(random_state=1)\n",
    "# alg = GradientBoostingClassifier()\n",
    "nn = Sequential()\n",
    "nn.add(Dense(len(predictors), output_dim=5, activation='tanh'))\n",
    "nn.add(Dense(5, output_dim=5, activation='tanh'))\n",
    "nn.add(Dense(5, output_dim=2, activation='softmax'))\n",
    "nn.compile(loss='mean_squared_error', optimizer='sgd')\n",
    "\n",
    "kf = KFold(titanic.shape[0], n_folds=10, random_state=1)\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_predictors = titanic[predictors].as_matrix()[train,:]\n",
    "    target = class_to_vect(titanic.Survived.as_matrix())\n",
    "    target_train = class_to_vect(titanic.Survived.iloc[train].as_matrix())\n",
    "    nn.fit(train_predictors, target[train], nb_epoch=30, show_accuracy=True, validation_split=0.1)\n",
    "    test_predictions = nn.predict_classes(titanic[predictors].as_matrix()[test,:])\n",
    "    predictions.append(test_predictions)\n",
    "predictions = np.concatenate(predictions)\n",
    "\n",
    "\n",
    "# for i in range(10, 200, 10):\n",
    "#     alg = AdaBoostClassifier(n_estimators=80)\n",
    "#     alg = KNeighborsClassifier(n_neighbors=i)\n",
    "#     alg = RandomForestClassifier(random_state=0, n_estimators=i, min_samples_split=4, min_samples_leaf=2)\n",
    "# scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "# score_means.append(scores.mean())\n",
    "# # plt.plot(score_means)\n",
    "# print(score_means)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6767676767676768\n"
     ]
    }
   ],
   "source": [
    "def perc_score(actual, prediction):\n",
    "    error = 0\n",
    "    N = len(predictions)\n",
    "    for i in range(N):\n",
    "        if predictions[i] == actual.iloc[i]:\n",
    "            error += 1\n",
    "    return float(error) / N\n",
    "\n",
    "print(perc_score(titanic.Survived, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# processing test data \n",
    "\n",
    "test_data[\"Age\"] = test_data[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "test_data[\"Embarked\"] = test_data[\"Embarked\"].fillna(\"S\")\n",
    "test_data[\"Fare\"] = test_data[\"Fare\"].fillna(titanic[\"Fare\"].median())\n",
    "\n",
    "# new features\n",
    "test_data[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"]\n",
    "test_data[\"NameLength\"] = test_data[\"Name\"].apply(lambda x: len(x))\n",
    "test_data[\"Title\"] = test_data[\"Name\"].apply(get_title)\n",
    "\n",
    "for col in train_columns_to_encode:\n",
    "    test_data[col] = columns_labels.fit_transform(test_data[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 801 samples, validate on 90 samples\n",
      "Epoch 0\n",
      "801/801 [==============================] - 0s - loss: 0.2416 - acc: 0.6155 - val_loss: 0.2411 - val_acc: 0.6222\n",
      "Epoch 1\n",
      "801/801 [==============================] - 0s - loss: 0.2415 - acc: 0.6155 - val_loss: 0.2409 - val_acc: 0.6222\n",
      "Epoch 2\n",
      "801/801 [==============================] - 0s - loss: 0.2413 - acc: 0.6155 - val_loss: 0.2407 - val_acc: 0.6222\n",
      "Epoch 3\n",
      "801/801 [==============================] - 0s - loss: 0.2411 - acc: 0.6155 - val_loss: 0.2404 - val_acc: 0.6222\n",
      "Epoch 4\n",
      "801/801 [==============================] - 0s - loss: 0.2409 - acc: 0.6155 - val_loss: 0.2402 - val_acc: 0.6222\n",
      "Epoch 5\n",
      "801/801 [==============================] - 0s - loss: 0.2407 - acc: 0.6155 - val_loss: 0.2400 - val_acc: 0.6222\n",
      "Epoch 6\n",
      "801/801 [==============================] - 0s - loss: 0.2405 - acc: 0.6155 - val_loss: 0.2398 - val_acc: 0.6222\n",
      "Epoch 7\n",
      "801/801 [==============================] - 0s - loss: 0.2403 - acc: 0.6155 - val_loss: 0.2396 - val_acc: 0.6222\n",
      "Epoch 8\n",
      "801/801 [==============================] - 0s - loss: 0.2402 - acc: 0.6155 - val_loss: 0.2395 - val_acc: 0.6222\n",
      "Epoch 9\n",
      "801/801 [==============================] - 0s - loss: 0.2400 - acc: 0.6155 - val_loss: 0.2393 - val_acc: 0.6222\n",
      "Epoch 10\n",
      "801/801 [==============================] - 0s - loss: 0.2399 - acc: 0.6155 - val_loss: 0.2392 - val_acc: 0.6222\n",
      "Epoch 11\n",
      "801/801 [==============================] - 0s - loss: 0.2398 - acc: 0.6155 - val_loss: 0.2390 - val_acc: 0.6222\n",
      "Epoch 12\n",
      "801/801 [==============================] - 0s - loss: 0.2396 - acc: 0.6155 - val_loss: 0.2388 - val_acc: 0.6222\n",
      "Epoch 13\n",
      "801/801 [==============================] - 0s - loss: 0.2395 - acc: 0.6155 - val_loss: 0.2387 - val_acc: 0.6222\n",
      "Epoch 14\n",
      "801/801 [==============================] - 0s - loss: 0.2394 - acc: 0.6155 - val_loss: 0.2385 - val_acc: 0.6222\n",
      "Epoch 15\n",
      "801/801 [==============================] - 0s - loss: 0.2392 - acc: 0.6155 - val_loss: 0.2384 - val_acc: 0.6222\n",
      "Epoch 16\n",
      "801/801 [==============================] - 0s - loss: 0.2391 - acc: 0.6155 - val_loss: 0.2383 - val_acc: 0.6222\n",
      "Epoch 17\n",
      "801/801 [==============================] - 0s - loss: 0.2390 - acc: 0.6155 - val_loss: 0.2381 - val_acc: 0.6222\n",
      "Epoch 18\n",
      "801/801 [==============================] - 0s - loss: 0.2389 - acc: 0.6155 - val_loss: 0.2380 - val_acc: 0.6222\n",
      "Epoch 19\n",
      "801/801 [==============================] - 0s - loss: 0.2388 - acc: 0.6155 - val_loss: 0.2379 - val_acc: 0.6222\n",
      "Epoch 20\n",
      "801/801 [==============================] - 0s - loss: 0.2387 - acc: 0.6155 - val_loss: 0.2378 - val_acc: 0.6222\n",
      "Epoch 21\n",
      "801/801 [==============================] - 0s - loss: 0.2386 - acc: 0.6155 - val_loss: 0.2376 - val_acc: 0.6222\n",
      "Epoch 22\n",
      "801/801 [==============================] - 0s - loss: 0.2384 - acc: 0.6155 - val_loss: 0.2375 - val_acc: 0.6222\n",
      "Epoch 23\n",
      "801/801 [==============================] - 0s - loss: 0.2384 - acc: 0.6155 - val_loss: 0.2374 - val_acc: 0.6222\n",
      "Epoch 24\n",
      "801/801 [==============================] - 0s - loss: 0.2383 - acc: 0.6155 - val_loss: 0.2373 - val_acc: 0.6222\n",
      "Epoch 25\n",
      "801/801 [==============================] - 0s - loss: 0.2382 - acc: 0.6155 - val_loss: 0.2372 - val_acc: 0.6222\n",
      "Epoch 26\n",
      "801/801 [==============================] - 0s - loss: 0.2381 - acc: 0.6155 - val_loss: 0.2371 - val_acc: 0.6222\n",
      "Epoch 27\n",
      "801/801 [==============================] - 0s - loss: 0.2380 - acc: 0.6155 - val_loss: 0.2370 - val_acc: 0.6222\n",
      "Epoch 28\n",
      "801/801 [==============================] - 0s - loss: 0.2379 - acc: 0.6155 - val_loss: 0.2369 - val_acc: 0.6222\n",
      "Epoch 29\n",
      "801/801 [==============================] - 0s - loss: 0.2379 - acc: 0.6155 - val_loss: 0.2369 - val_acc: 0.6222\n",
      "418/418 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "# predict test data\n",
    "\n",
    "# alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "nn.fit(titanic[predictors].as_matrix(), class_to_vect(titanic.Survived.as_matrix()), nb_epoch=30, show_accuracy=True, validation_split=0.1)\n",
    "predictions = nn.predict_classes(test_data[predictors].as_matrix())\n",
    "\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": test_data[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "submission.to_csv(\"kaggle_titanic/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
