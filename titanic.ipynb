{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas\n",
    "\n",
    "titanic = pandas.read_csv(\"kaggle_titanic/train.csv\")\n",
    "test_data = pandas.read_csv(\"kaggle_titanic/test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preprocessing\n",
    "\n",
    "import re\n",
    "from sklearn import preprocessing\n",
    "\n",
    "def get_title(name):\n",
    "    title_search = re.search(' ([A-Za-z]+)\\.', name)\n",
    "    if title_search:\n",
    "        return title_search.group(1)\n",
    "    return \"\"\n",
    "\n",
    "def get_age_group(age):\n",
    "    if age < 15:\n",
    "        return 0\n",
    "    if age < 50:\n",
    "        return 1\n",
    "    return 2\n",
    "\n",
    "titanic[\"Age\"] = titanic[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "titanic[\"Embarked\"] = titanic[\"Embarked\"].fillna(\"S\")\n",
    "\n",
    "# new features\n",
    "titanic[\"FamilySize\"] = titanic[\"SibSp\"] + titanic[\"Parch\"]\n",
    "titanic[\"NameLength\"] = titanic[\"Name\"].apply(lambda x: len(x))\n",
    "titanic[\"Title\"] = titanic[\"Name\"].apply(get_title)\n",
    "# titanic[\"Age\"]  = titanic[\"Age\"].apply(get_age_group)\n",
    "\n",
    "columns_labels = preprocessing.LabelEncoder()\n",
    "train_columns_to_encode = ['Sex', 'Embarked', 'Title']\n",
    "\n",
    "for col in train_columns_to_encode:\n",
    "    titanic[col] = columns_labels.fit_transform(titanic[col])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# features exctractin\n",
    "\n",
    "from sklearn import cross_validation\n",
    "from sklearn.feature_selection import SelectKBest, f_classif\n",
    "\n",
    "predictors = [\"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Embarked\", \"Title\"]\n",
    "\n",
    "# selector = SelectKBest(f_classif, k=5)\n",
    "# selector.fit(titanic[predictors], titanic[\"Survived\"])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def class_to_vect(classification):\n",
    "    cls_count = 2\n",
    "    vect = []\n",
    "    for cls in classification:\n",
    "        v = [0] * cls_count\n",
    "        v[cls] = 1\n",
    "        vect.append(v)\n",
    "    return np.array(vect)\n",
    "\n",
    "def get_binary_two_outputs(pred_probs):\n",
    "    results = []\n",
    "    for p1, p2 in pred_probs:\n",
    "        if p1 > p2:\n",
    "            results.append(0)\n",
    "        else:\n",
    "            results.append(1)\n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Two outputs approach:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "594/594 [==============================] - 0s - loss: 0.2622 - acc: 0.4680     \n",
      "Epoch 1\n",
      "594/594 [==============================] - 0s - loss: 0.2521 - acc: 0.5791     \n",
      "Epoch 2\n",
      "594/594 [==============================] - 0s - loss: 0.2467 - acc: 0.5825     \n",
      "Epoch 3\n",
      "594/594 [==============================] - 0s - loss: 0.2426 - acc: 0.5842     \n",
      "Epoch 4\n",
      "594/594 [==============================] - 0s - loss: 0.2392 - acc: 0.5926     \n",
      "Epoch 5\n",
      "594/594 [==============================] - 0s - loss: 0.2362 - acc: 0.5926     \n",
      "Epoch 6\n",
      "594/594 [==============================] - 0s - loss: 0.2336 - acc: 0.5943     \n",
      "Epoch 7\n",
      "594/594 [==============================] - 0s - loss: 0.2304 - acc: 0.5943     \n",
      "Epoch 8\n",
      "594/594 [==============================] - 0s - loss: 0.2276 - acc: 0.5960     \n",
      "Epoch 9\n",
      "594/594 [==============================] - 0s - loss: 0.2251 - acc: 0.6094     \n",
      "Epoch 10\n",
      "594/594 [==============================] - 0s - loss: 0.2224 - acc: 0.6397     \n",
      "Epoch 11\n",
      "594/594 [==============================] - 0s - loss: 0.2195 - acc: 0.6397     \n",
      "Epoch 12\n",
      "594/594 [==============================] - 0s - loss: 0.2173 - acc: 0.6532     \n",
      "Epoch 13\n",
      "594/594 [==============================] - 0s - loss: 0.2144 - acc: 0.6835     \n",
      "Epoch 14\n",
      "594/594 [==============================] - 0s - loss: 0.2120 - acc: 0.6818     \n",
      "Epoch 15\n",
      "594/594 [==============================] - 0s - loss: 0.2094 - acc: 0.6987     \n",
      "Epoch 16\n",
      "594/594 [==============================] - 0s - loss: 0.2069 - acc: 0.7003     \n",
      "Epoch 17\n",
      "594/594 [==============================] - 0s - loss: 0.2043 - acc: 0.7088     \n",
      "Epoch 18\n",
      "594/594 [==============================] - 0s - loss: 0.2018 - acc: 0.7155     \n",
      "Epoch 19\n",
      "594/594 [==============================] - 0s - loss: 0.1995 - acc: 0.7172     \n",
      "297/297 [==============================] - 0s     \n",
      "Epoch 0\n",
      "594/594 [==============================] - 0s - loss: 0.1992 - acc: 0.7357     \n",
      "Epoch 1\n",
      "594/594 [==============================] - 0s - loss: 0.1969 - acc: 0.7189     \n",
      "Epoch 2\n",
      "594/594 [==============================] - 0s - loss: 0.1956 - acc: 0.7239     \n",
      "Epoch 3\n",
      "594/594 [==============================] - 0s - loss: 0.1936 - acc: 0.7273     \n",
      "Epoch 4\n",
      "594/594 [==============================] - 0s - loss: 0.1922 - acc: 0.7492     \n",
      "Epoch 5\n",
      "594/594 [==============================] - 0s - loss: 0.1906 - acc: 0.7407     \n",
      "Epoch 6\n",
      "594/594 [==============================] - 0s - loss: 0.1895 - acc: 0.7441     \n",
      "Epoch 7\n",
      "594/594 [==============================] - 0s - loss: 0.1874 - acc: 0.7508     \n",
      "Epoch 8\n",
      "594/594 [==============================] - 0s - loss: 0.1861 - acc: 0.7508     \n",
      "Epoch 9\n",
      "594/594 [==============================] - 0s - loss: 0.1843 - acc: 0.7525     \n",
      "Epoch 10\n",
      "594/594 [==============================] - 0s - loss: 0.1830 - acc: 0.7542     \n",
      "Epoch 11\n",
      "594/594 [==============================] - 0s - loss: 0.1818 - acc: 0.7576     \n",
      "Epoch 12\n",
      "594/594 [==============================] - 0s - loss: 0.1802 - acc: 0.7593     \n",
      "Epoch 13\n",
      "594/594 [==============================] - 0s - loss: 0.1783 - acc: 0.7576     \n",
      "Epoch 14\n",
      "594/594 [==============================] - 0s - loss: 0.1773 - acc: 0.7609     \n",
      "Epoch 15\n",
      "594/594 [==============================] - 0s - loss: 0.1759 - acc: 0.7576     \n",
      "Epoch 16\n",
      "594/594 [==============================] - 0s - loss: 0.1741 - acc: 0.7593     \n",
      "Epoch 17\n",
      "594/594 [==============================] - 0s - loss: 0.1731 - acc: 0.7643     \n",
      "Epoch 18\n",
      "594/594 [==============================] - 0s - loss: 0.1710 - acc: 0.7609     \n",
      "Epoch 19\n",
      "594/594 [==============================] - 0s - loss: 0.1697 - acc: 0.7660     \n",
      "297/297 [==============================] - 0s     \n",
      "Epoch 0\n",
      "594/594 [==============================] - 0s - loss: 0.1735 - acc: 0.7424     \n",
      "Epoch 1\n",
      "594/594 [==============================] - 0s - loss: 0.1726 - acc: 0.7458     \n",
      "Epoch 2\n",
      "594/594 [==============================] - 0s - loss: 0.1709 - acc: 0.7559     \n",
      "Epoch 3\n",
      "594/594 [==============================] - 0s - loss: 0.1697 - acc: 0.7626     \n",
      "Epoch 4\n",
      "594/594 [==============================] - 0s - loss: 0.1681 - acc: 0.7593     \n",
      "Epoch 5\n",
      "594/594 [==============================] - 0s - loss: 0.1668 - acc: 0.7660     \n",
      "Epoch 6\n",
      "594/594 [==============================] - 0s - loss: 0.1656 - acc: 0.7727     \n",
      "Epoch 7\n",
      "594/594 [==============================] - 0s - loss: 0.1663 - acc: 0.7660     \n",
      "Epoch 8\n",
      "594/594 [==============================] - 0s - loss: 0.1638 - acc: 0.7828     \n",
      "Epoch 9\n",
      "594/594 [==============================] - 0s - loss: 0.1620 - acc: 0.7795     \n",
      "Epoch 10\n",
      "594/594 [==============================] - 0s - loss: 0.1612 - acc: 0.7778     \n",
      "Epoch 11\n",
      "594/594 [==============================] - 0s - loss: 0.1612 - acc: 0.7845     \n",
      "Epoch 12\n",
      "594/594 [==============================] - 0s - loss: 0.1596 - acc: 0.7845     \n",
      "Epoch 13\n",
      "594/594 [==============================] - 0s - loss: 0.1590 - acc: 0.7811     \n",
      "Epoch 14\n",
      "594/594 [==============================] - 0s - loss: 0.1582 - acc: 0.7879     \n",
      "Epoch 15\n",
      "594/594 [==============================] - 0s - loss: 0.1577 - acc: 0.7879     \n",
      "Epoch 16\n",
      "594/594 [==============================] - 0s - loss: 0.1564 - acc: 0.7845     \n",
      "Epoch 17\n",
      "594/594 [==============================] - 0s - loss: 0.1560 - acc: 0.7896     \n",
      "Epoch 18\n",
      "594/594 [==============================] - 0s - loss: 0.1562 - acc: 0.7845     \n",
      "Epoch 19\n",
      "594/594 [==============================] - 0s - loss: 0.1550 - acc: 0.7879     \n",
      "297/297 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "# classification and cross validation\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier, AdaBoostClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from sklearn.cross_validation import KFold\n",
    "from keras.layers.core import Dense, Dropout, Activation\n",
    "\n",
    "# alg = LogisticRegression(random_state=1)\n",
    "# alg = GradientBoostingClassifier()\n",
    "nn = Sequential()\n",
    "nn.add(Dense(len(predictors), output_dim=10, activation='tanh'))\n",
    "nn.add(Dense(10, output_dim=10, activation='tanh'))\n",
    "nn.add(Dense(10, output_dim=2, activation='softmax'))\n",
    "nn.compile(loss='mean_squared_error', optimizer='RMSprop')\n",
    "\n",
    "kf = KFold(titanic.shape[0], n_folds=3, random_state=1)\n",
    "predictions = []\n",
    "for train, test in kf:\n",
    "    train_predictors = titanic[predictors].as_matrix()[train,:]\n",
    "    target = class_to_vect(titanic.Survived.as_matrix())\n",
    "    target_train = class_to_vect(titanic.Survived.iloc[train].as_matrix())\n",
    "    nn.fit(train_predictors, target[train], nb_epoch=20, show_accuracy=True)\n",
    "    test_predictions = nn.predict_classes(titanic[predictors].as_matrix()[test,:])\n",
    "    predictions.append(test_predictions)\n",
    "predictions = np.concatenate(predictions)\n",
    "\n",
    "# for i in range(10, 200, 10):\n",
    "#     alg = AdaBoostClassifier(n_estimators=80)\n",
    "#     alg = KNeighborsClassifier(n_neighbors=i)\n",
    "#     alg = RandomForestClassifier(random_state=0, n_estimators=i, min_samples_split=4, min_samples_leaf=2)\n",
    "# scores = cross_validation.cross_val_score(alg, titanic[predictors], titanic[\"Survived\"], cv=3)\n",
    "# score_means.append(scores.mean())\n",
    "# # plt.plot(score_means)\n",
    "# print(score_means)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n"
     ]
    }
   ],
   "source": [
    "def perc_score(actual, prediction):\n",
    "    error = 0\n",
    "    N = len(predictions)\n",
    "    for i in range(N):\n",
    "        if predictions[i] != actual[i]:\n",
    "            error += 1\n",
    "    return float(error) / N\n",
    "\n",
    "print(perc_score(predictions, titanic.Survived))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# processing test data \n",
    "\n",
    "test_data[\"Age\"] = test_data[\"Age\"].fillna(titanic[\"Age\"].median())\n",
    "test_data[\"Embarked\"] = test_data[\"Embarked\"].fillna(\"S\")\n",
    "test_data[\"Fare\"] = test_data[\"Fare\"].fillna(titanic[\"Fare\"].median())\n",
    "\n",
    "# new features\n",
    "test_data[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"]\n",
    "test_data[\"NameLength\"] = test_data[\"Name\"].apply(lambda x: len(x))\n",
    "test_data[\"Title\"] = test_data[\"Name\"].apply(get_title)\n",
    "\n",
    "for col in train_columns_to_encode:\n",
    "    test_data[col] = columns_labels.fit_transform(test_data[col])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n",
      "891/891 [==============================] - 0s - loss: 0.1382 - acc: 0.8103     \n",
      "Epoch 1\n",
      "891/891 [==============================] - 0s - loss: 0.1377 - acc: 0.8114     \n",
      "Epoch 2\n",
      "891/891 [==============================] - 0s - loss: 0.1373 - acc: 0.8114     \n",
      "Epoch 3\n",
      "891/891 [==============================] - 0s - loss: 0.1377 - acc: 0.8114     \n",
      "Epoch 4\n",
      "891/891 [==============================] - 0s - loss: 0.1379 - acc: 0.8036     \n",
      "Epoch 5\n",
      "891/891 [==============================] - 0s - loss: 0.1378 - acc: 0.8126     \n",
      "Epoch 6\n",
      "891/891 [==============================] - 0s - loss: 0.1375 - acc: 0.8047     \n",
      "Epoch 7\n",
      "891/891 [==============================] - 0s - loss: 0.1369 - acc: 0.8103     \n",
      "Epoch 8\n",
      "891/891 [==============================] - 0s - loss: 0.1370 - acc: 0.8081     \n",
      "Epoch 9\n",
      "891/891 [==============================] - 0s - loss: 0.1368 - acc: 0.8114     \n",
      "Epoch 10\n",
      "891/891 [==============================] - 0s - loss: 0.1369 - acc: 0.8081     \n",
      "Epoch 11\n",
      "891/891 [==============================] - 0s - loss: 0.1364 - acc: 0.8114     \n",
      "Epoch 12\n",
      "891/891 [==============================] - 0s - loss: 0.1369 - acc: 0.8092     \n",
      "Epoch 13\n",
      "891/891 [==============================] - 0s - loss: 0.1359 - acc: 0.8092     \n",
      "Epoch 14\n",
      "891/891 [==============================] - 0s - loss: 0.1367 - acc: 0.8047     \n",
      "Epoch 15\n",
      "891/891 [==============================] - 0s - loss: 0.1359 - acc: 0.8081     \n",
      "Epoch 16\n",
      "891/891 [==============================] - 0s - loss: 0.1356 - acc: 0.8103     \n",
      "Epoch 17\n",
      "891/891 [==============================] - 0s - loss: 0.1357 - acc: 0.8081     \n",
      "Epoch 18\n",
      "891/891 [==============================] - 0s - loss: 0.1352 - acc: 0.8081     \n",
      "Epoch 19\n",
      "891/891 [==============================] - 0s - loss: 0.1357 - acc: 0.8114     \n",
      "418/418 [==============================] - 0s     \n"
     ]
    }
   ],
   "source": [
    "# predict test data\n",
    "\n",
    "# alg.fit(titanic[predictors], titanic[\"Survived\"])\n",
    "nn.fit(titanic[predictors].as_matrix(), class_to_vect(titanic.Survived.as_matrix()), nb_epoch=20, show_accuracy=True)\n",
    "predictions = nn.predict_classes(test_data[predictors].as_matrix())\n",
    "\n",
    "submission = pandas.DataFrame({\n",
    "        \"PassengerId\": test_data[\"PassengerId\"],\n",
    "        \"Survived\": predictions\n",
    "    })\n",
    "submission.to_csv(\"kaggle_titanic/submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
